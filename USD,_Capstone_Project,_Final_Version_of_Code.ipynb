{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP9aEyE/UwaDabC/zBHxuJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yaakov-Sternberg/USD-Capstone-Project-to-Predict-Preterm-Infant-Bradycardia-Events-/blob/main/USD%2C_Capstone_Project%2C_Final_Version_of_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb xgboost --quiet\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, roc_curve,\n",
        "    precision_recall_curve, confusion_matrix, accuracy_score\n",
        ")\n",
        "\n",
        "import xgboost as xgb\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.cuda.amp as amp\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import wfdb\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Seed for reproducibility\n",
        "RANDOM_SEED = 1234\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    \"\"\"Ensures DataLoader workers are also deterministic.\"\"\"\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "set_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Setup complete. Device: {device}\")"
      ],
      "metadata": {
        "id": "Ds-63yfBJue2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e99210d-6d7d-44db-c9c7-d133fe49770a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSetup complete. Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "3VX8L_hLIHu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Central configuration.\"\"\"\n",
        "    EXPERIMENT_NAME = \"Merged_Optimized_Diagnostics\"\n",
        "\n",
        "    # Paths\n",
        "    DRIVE_PATH = '/content/drive/MyDrive/picsdb'\n",
        "    LOCAL_PATH = '/content/picsdb_local'\n",
        "    RESULTS_BASE = '/content/drive/MyDrive/capstone_results'\n",
        "\n",
        "    # Data parameters\n",
        "    FS_GRID = 2.0\n",
        "    WINDOW_LEN = 120.0\n",
        "    HORIZON = 60.0\n",
        "\n",
        "    # Dual Stride approaches for imbalance handling\n",
        "    STRIDE = 10.0            # Normal Stride\n",
        "    DENSE_STRIDE = 2.0       # Stride for positive regions\n",
        "    POS_REGION_RADIUS = 90.0 # Seconds around brady event to sample densely\n",
        "\n",
        "    LEAD_TIME = 0.5\n",
        "    HR_CLIP_MIN = 40.0\n",
        "    HR_CLIP_MAX = 220.0\n",
        "\n",
        "    # Frequency Domain Features (HRV)\n",
        "    LF_BAND = (0.04, 0.15)\n",
        "    HF_BAND = (0.15, 0.4)\n",
        "\n",
        "    # Split ratios\n",
        "    TEMPORAL_TRAIN_RATIO = 0.7\n",
        "    TEMPORAL_VAL_RATIO = 0.15\n",
        "    HYBRID_WARMUP_RATIO = 0.3\n",
        "\n",
        "    # Training\n",
        "    BATCH_SIZE = 128\n",
        "    LEARNING_RATE = 1e-3\n",
        "    N_EPOCHS = 30\n",
        "    PATIENCE = 7\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "    DROPOUT = 0.3\n",
        "    MAX_POS_WEIGHT = 3.0\n",
        "    GRAD_CLIP = 1.0\n",
        "\n",
        "    # Oversampling: Target fraction of positives in each training batch\n",
        "    TARGET_POSITIVE_RATIO = 0.3\n",
        "\n",
        "    # Minimum FP penalty near events\n",
        "    MIN_FP_WEIGHT = 0.2\n",
        "\n",
        "    # Speed Optimization\n",
        "    NUM_WORKERS = min(4, os.cpu_count() or 2)\n",
        "    USE_TORCH_COMPILE = True\n",
        "\n",
        "    # Diagnostic Thresholds\n",
        "    OVERFIT_GAP_THRESHOLD = 0.10\n",
        "    UNDERFIT_AUROC_THRESHOLD = 0.60\n",
        "\n",
        "    # Models to run\n",
        "    MODELS = ('CNN-BiLSTM', 'TCN', 'XGBoost', 'Random Forest', 'Logistic Regression')\n",
        "\n",
        "\n",
        "config = Config()\n",
        "\n",
        "OUTPUT_DIR = os.path.join(config.RESULTS_BASE, config.EXPERIMENT_NAME)\n",
        "PROGRESS_FILE = os.path.join(OUTPUT_DIR, 'progress.json')\n",
        "\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "fig_dir = os.path.join(OUTPUT_DIR, 'figures')\n",
        "os.makedirs(fig_dir, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs-qd4aJIPoW",
        "outputId": "1fdf41e7-9f80-4248-b091-b0746ccdb567"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory: /content/drive/MyDrive/capstone_results/Merged_Optimized_Diagnostics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoint/resume logic"
      ],
      "metadata": {
        "id": "G7PDrUInItuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProgressTracker:\n",
        "    def __init__(self, progress_file: str):\n",
        "        self.progress_file = progress_file\n",
        "        self.progress = self._load_progress()\n",
        "\n",
        "    def _load_progress(self) -> dict:\n",
        "        if os.path.exists(self.progress_file):\n",
        "            with open(self.progress_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {'started_at': datetime.now().isoformat(), 'completed': [], 'failed': []}\n",
        "\n",
        "    def _save_progress(self):\n",
        "        self.progress['last_updated'] = datetime.now().isoformat()\n",
        "        temp_file = self.progress_file + '.tmp'\n",
        "        with open(temp_file, 'w') as f:\n",
        "            json.dump(self.progress, f, indent=2)\n",
        "        os.replace(temp_file, self.progress_file)\n",
        "\n",
        "\n",
        "    def is_completed(self, task_id: str) -> bool:\n",
        "        return task_id in self.progress['completed']\n",
        "\n",
        "    def mark_completed(self, task_id: str):\n",
        "        if task_id not in self.progress['completed']:\n",
        "            self.progress['completed'].append(task_id)\n",
        "            self._save_progress()\n",
        "            print(f\"Checkpoint saved: {task_id}\")\n",
        "\n",
        "    def mark_failed(self, task_id: str, error: str):\n",
        "        self.progress['failed'].append({'task': task_id, 'error': error, 'time': datetime.now().isoformat()})\n",
        "        self._save_progress()\n"
      ],
      "metadata": {
        "id": "ZclKgxeCId-d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive & Setup"
      ],
      "metadata": {
        "id": "ITW1hHaOI5KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Check if Drive is mounted\n",
        "if os.path.ismount('/content/drive'):\n",
        "    print(\"Google Drive is already successfully mounted.\")\n",
        "\n",
        "else:\n",
        "    # If not mounted, check for folder blocking\n",
        "    if os.path.exists('/content/drive'):\n",
        "        print(\"Found a blocking '/content/drive' folder. Cleaning it up...\")\n",
        "        # Deletes folder\n",
        "        shutil.rmtree('/content/drive')\n",
        "\n",
        "    # Create a fresh empty directory\n",
        "    os.makedirs('/content/drive', exist_ok=True)\n",
        "\n",
        "    # Mount with force_remount\n",
        "    print(\"Attempting to mount...\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Continue with directory setup\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "for subdir in ['models', 'predictions', 'figures', 'data',\n",
        "               'figures/learning_curves', 'figures/learning_curves_traditional',\n",
        "               'loso/models', 'loso/predictions',\n",
        "               'temporal/models', 'temporal/predictions',\n",
        "               'hybrid/models', 'hybrid/predictions']:\n",
        "    os.makedirs(os.path.join(OUTPUT_DIR, subdir), exist_ok=True)\n",
        "\n",
        "tracker = ProgressTracker(PROGRESS_FILE)\n",
        "\n",
        "if os.path.exists(config.DRIVE_PATH) and not os.path.exists(config.LOCAL_PATH):\n",
        "    print(\"Copying data to local storage...\")\n",
        "    shutil.copytree(config.DRIVE_PATH, config.LOCAL_PATH)\n",
        "    print(\"Data ready\")\n",
        "elif not os.path.exists(config.LOCAL_PATH):\n",
        "    print(f\"Warning: Data path {config.LOCAL_PATH} does not exist.\")\n",
        "else:\n",
        "    print(\"Data directory already exists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC4Zkq-WI-lB",
        "outputId": "13fc135e-c0e0-4be6-f803-6888c223a688"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found a blocking '/content/drive' folder. Cleaning it up...\n",
            "Attempting to mount...\n",
            "Mounted at /content/drive\n",
            "Copying data to local storage...\n",
            "Data ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting"
      ],
      "metadata": {
        "id": "MvJAjdYdJL3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(history, model_name, subject_id, save_dir):\n",
        "    epochs = np.arange(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Plot 1: Loss Curves\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
        "    ax1.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
        "    ax1.fill_between(epochs, history['train_loss'], history['val_loss'], alpha=0.3, color='orange', label='Gap')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('BCE Loss')\n",
        "    ax1.set_title(f'Loss Curves - {model_name} ({subject_id})')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Gap Annotation\n",
        "    final_loss_gap = history['val_loss'][-1] - history['train_loss'][-1]\n",
        "    ax1.annotate(f'Final Gap: {final_loss_gap:.4f}', xy=(0.95, 0.95), xycoords='axes fraction',\n",
        "                 ha='right', va='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # Plot 2: AUROC Curves\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.plot(epochs, history['train_auroc'], 'b-', label='Train AUROC', linewidth=2)\n",
        "    ax2.plot(epochs, history['val_auroc'], 'r-', label='Val AUROC', linewidth=2)\n",
        "    ax2.axhline(0.5, color='gray', linestyle='--')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('AUROC')\n",
        "    ax2.set_title('AUROC Curves')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    auroc_gap = history['train_auroc'][-1] - history['val_auroc'][-1]\n",
        "    ax2.annotate(f'Train-Val Gap: {auroc_gap:.4f}', xy=(0.95, 0.05), xycoords='axes fraction',\n",
        "                 ha='right', va='bottom', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # Plot 3: Accuracy Curves\n",
        "    ax3 = axes[1, 0]\n",
        "    ax3.plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
        "    ax3.plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Accuracy')\n",
        "    ax3.set_title('Accuracy Curves')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 4: Diagnosis\n",
        "    ax4 = axes[1, 1]\n",
        "    ax4.axis('off')\n",
        "\n",
        "    if auroc_gap > config.OVERFIT_GAP_THRESHOLD:\n",
        "        diagnosis = \"OVERFITTING\"\n",
        "        explanation = f\"Train-Val AUROC gap ({auroc_gap:.3f}) exceeds {config.OVERFIT_GAP_THRESHOLD}\"\n",
        "    elif history['val_auroc'][-1] < config.UNDERFIT_AUROC_THRESHOLD:\n",
        "        diagnosis = \"UNDERFITTING\"\n",
        "        explanation = f\"Val AUROC ({history['val_auroc'][-1]:.3f}) < {config.UNDERFIT_AUROC_THRESHOLD}\"\n",
        "    else:\n",
        "        diagnosis = \"GOOD FIT\"\n",
        "        explanation = \"Healthy train-val gap with reasonable performance\"\n",
        "\n",
        "    diag_text = f\"DIAGNOSIS\\n{'='*20}\\n\\nFinal Tr Loss: {history['train_loss'][-1]:.4f}\\nFinal Va Loss: {history['val_loss'][-1]:.4f}\\n\\nFinal Tr AUROC: {history['train_auroc'][-1]:.4f}\\nFinal Va AUROC: {history['val_auroc'][-1]:.4f}\\n\\nResult: {diagnosis}\\n{explanation}\"\n",
        "\n",
        "    ax4.text(0.1, 0.9, diag_text, transform=ax4.transAxes, fontsize=10, verticalalignment='top',\n",
        "             fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    plt.savefig(os.path.join(save_dir, f\"curve_{model_name.replace(' ', '_')}_{subject_id}.png\"), dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # Updated return to include diagnosis data\n",
        "    return {\n",
        "        'diagnosis': diagnosis,\n",
        "        'explanation': explanation,\n",
        "        'auroc_gap': auroc_gap,\n",
        "        'loss_gap': final_loss_gap\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_traditional_learning_curves(history, model_name, subject_id, strategy, save_dir):\n",
        "    \"\"\"Plots learning dynamics for Traditional Models.\"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    if 'n_rounds' in history: # XGBoost\n",
        "        rounds = np.arange(1, history['n_rounds'] + 1)\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.plot(rounds, history['train_auroc'], label='Train')\n",
        "        plt.plot(rounds, history['val_auroc'], label='Val')\n",
        "        plt.title(f'{model_name} ({strategy}) – {subject_id}')\n",
        "        plt.xlabel('Rounds'); plt.ylabel('AUROC')\n",
        "        plt.legend(); plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(os.path.join(save_dir, f\"{model_name}_{strategy}_{subject_id}_lc.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    elif 'train_size' in history: # RF/LogReg\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.plot(history['train_size'], history['train_auroc'], marker='o', label='Train')\n",
        "        plt.plot(history['train_size'], history['val_auroc'], marker='o', label='Val')\n",
        "        plt.title(f'{model_name} Learning Curve\\n({strategy} – {subject_id})')\n",
        "        plt.xlabel('Train Size'); plt.ylabel('AUROC')\n",
        "        plt.legend(); plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(os.path.join(save_dir, f\"{model_name}_{strategy}_{subject_id}_lc.png\"))\n",
        "        plt.close()\n",
        "\n",
        "def plot_aggregate_learning_curves():\n",
        "    \"\"\"Aggregate DL learning curves (CNN-BiLSTM / TCN only).\"\"\"\n",
        "    print(\"\\nGenerating aggregate learning curves...\")\n",
        "\n",
        "    strategies = ['loso', 'temporal', 'hybrid']\n",
        "    agg_dir = os.path.join(fig_dir, 'aggregate')\n",
        "    os.makedirs(agg_dir, exist_ok=True)\n",
        "\n",
        "    required_keys = ['train_loss', 'val_loss', 'train_auroc', 'val_auroc']\n",
        "\n",
        "    for strategy in strategies:\n",
        "        model_dir = os.path.join(OUTPUT_DIR, strategy, 'models')\n",
        "        if not os.path.exists(model_dir):\n",
        "            continue\n",
        "\n",
        "        histories = []\n",
        "        for f in os.listdir(model_dir):\n",
        "            if not f.endswith('_history.npz'):\n",
        "                continue\n",
        "\n",
        "            path = os.path.join(model_dir, f)\n",
        "            try:\n",
        "                data = np.load(path, allow_pickle=True)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "            #  Only keep files that have ALL the deep-learning keys\n",
        "            if not all(k in data.files for k in required_keys):\n",
        "                # This is likely a traditional model history (e.g., XGBoost / RF / LogReg)\n",
        "                continue\n",
        "\n",
        "            histories.append({\n",
        "                'train_loss':  data['train_loss'].tolist(),\n",
        "                'val_loss':    data['val_loss'].tolist(),\n",
        "                'train_auroc': data['train_auroc'].tolist(),\n",
        "                'val_auroc':   data['val_auroc'].tolist(),\n",
        "            })\n",
        "\n",
        "        # If no valid DL histories for this strategy, skip it\n",
        "        if not histories:\n",
        "            continue\n",
        "\n",
        "        # Find maximum number of epochs across histories\n",
        "        max_epochs = max(len(h['train_loss']) for h in histories)\n",
        "\n",
        "        # Pad histories with NaNs for alignment\n",
        "        train_losses = np.array([\n",
        "            h['train_loss'] + [np.nan] * (max_epochs - len(h['train_loss']))\n",
        "            for h in histories\n",
        "        ])\n",
        "        val_losses = np.array([\n",
        "            h['val_loss'] + [np.nan] * (max_epochs - len(h['val_loss']))\n",
        "            for h in histories\n",
        "        ])\n",
        "        train_aurocs = np.array([\n",
        "            h['train_auroc'] + [np.nan] * (max_epochs - len(h['train_auroc']))\n",
        "            for h in histories\n",
        "        ])\n",
        "        val_aurocs = np.array([\n",
        "            h['val_auroc'] + [np.nan] * (max_epochs - len(h['val_auroc']))\n",
        "            for h in histories\n",
        "        ])\n",
        "\n",
        "        epochs = np.arange(1, max_epochs + 1)\n",
        "\n",
        "        # Compute means and stds, ignoring NaNs\n",
        "        mean_train_loss = np.nanmean(train_losses, axis=0)\n",
        "        mean_val_loss   = np.nanmean(val_losses, axis=0)\n",
        "        std_train_loss  = np.nanstd(train_losses, axis=0)\n",
        "        std_val_loss    = np.nanstd(val_losses, axis=0)\n",
        "\n",
        "        mean_train_auroc = np.nanmean(train_aurocs, axis=0)\n",
        "        mean_val_auroc   = np.nanmean(val_aurocs, axis=0)\n",
        "        std_train_auroc  = np.nanstd(train_aurocs, axis=0)\n",
        "        std_val_auroc    = np.nanstd(val_aurocs, axis=0)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Loss plot\n",
        "        ax1 = axes[0]\n",
        "        ax1.plot(epochs, mean_train_loss, 'b-', lw=2, label='Train')\n",
        "        ax1.plot(epochs, mean_val_loss,   'r-', lw=2, label='Val')\n",
        "        ax1.fill_between(\n",
        "            epochs,\n",
        "            mean_train_loss - std_train_loss,\n",
        "            mean_train_loss + std_train_loss,\n",
        "            alpha=0.2,\n",
        "            color='blue'\n",
        "        )\n",
        "        ax1.fill_between(\n",
        "            epochs,\n",
        "            mean_val_loss - std_val_loss,\n",
        "            mean_val_loss + std_val_loss,\n",
        "            alpha=0.2,\n",
        "            color='red'\n",
        "        )\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title(f'{strategy.upper()} - Aggregate Loss (n={len(histories)})')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # AUROC plot\n",
        "        ax2 = axes[1]\n",
        "        ax2.plot(epochs, mean_train_auroc, 'b-', lw=2, label='Train')\n",
        "        ax2.plot(epochs, mean_val_auroc,   'r-', lw=2, label='Val')\n",
        "        ax2.fill_between(\n",
        "            epochs,\n",
        "            mean_train_auroc - std_train_auroc,\n",
        "            mean_train_auroc + std_train_auroc,\n",
        "            alpha=0.2,\n",
        "            color='blue'\n",
        "        )\n",
        "        ax2.fill_between(\n",
        "            epochs,\n",
        "            mean_val_auroc - std_val_auroc,\n",
        "            mean_val_auroc + std_val_auroc,\n",
        "            alpha=0.2,\n",
        "            color='red'\n",
        "        )\n",
        "        ax2.axhline(0.5, color='gray', ls='--')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('AUROC')\n",
        "        ax2.set_title(f'{strategy.upper()} - Aggregate AUROC')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.set_ylim(0.4, 1.0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        out_path = os.path.join(agg_dir, f'aggregate_{strategy}_curves.png')\n",
        "        plt.savefig(out_path, dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"  Saved aggregate curves for {strategy.upper()} to {out_path}\")\n",
        "\n",
        "def plot_overfitting_analysis(results_df):\n",
        "    \"\"\"\n",
        "    Create an overfitting analysis scatter plot:\n",
        "    Train AUROC vs Val AUROC for each run, by strategy and model.\n",
        "    \"\"\"\n",
        "    print(\"\\nGenerating overfitting analysis plot...\")\n",
        "\n",
        "    # If train_auroc was not saved, we can't do this plot\n",
        "    if 'train_auroc' not in results_df.columns or 'val_auroc' not in results_df.columns:\n",
        "        print(\"  train_auroc / val_auroc not found in results_df – skipping overfitting analysis.\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    strategies = ['LOSO', 'Temporal', 'Hybrid']\n",
        "\n",
        "    for idx, strategy in enumerate(strategies):\n",
        "        ax = axes[idx]\n",
        "        subset = results_df[results_df['strategy'] == strategy]\n",
        "\n",
        "        if len(subset) == 0:\n",
        "            ax.axis('off')\n",
        "            ax.set_title(f'{strategy}\\n(no runs)')\n",
        "            continue\n",
        "\n",
        "        # Scatter: Train AUROC vs Val AUROC, colored by model\n",
        "        for model in config.MODELS:\n",
        "            model_subset = subset[subset['model'] == model]\n",
        "            if len(model_subset) == 0:\n",
        "                continue\n",
        "            ax.scatter(\n",
        "                model_subset['train_auroc'],\n",
        "                model_subset['val_auroc'],\n",
        "                label=model,\n",
        "                alpha=0.7,\n",
        "                s=50\n",
        "            )\n",
        "\n",
        "        # Diagonal \"perfect generalization\" line\n",
        "        ax.plot([0.4, 1.0], [0.4, 1.0], 'k--', alpha=0.5, label='Perfect')\n",
        "\n",
        "        # Overfitting good-fit zone\n",
        "        lower_good = np.array([0.4 - config.OVERFIT_GAP_THRESHOLD, 1.0 - config.OVERFIT_GAP_THRESHOLD])\n",
        "        upper_good = np.array([0.4, 1.0])\n",
        "        ax.fill_between(\n",
        "            [0.4, 1.0],\n",
        "            lower_good,\n",
        "            upper_good,\n",
        "            alpha=0.1,\n",
        "            color='green',\n",
        "            label='Good fit zone'\n",
        "        )\n",
        "\n",
        "        ax.set_xlabel('Train AUROC')\n",
        "        ax.set_ylabel('Val AUROC')\n",
        "        ax.set_title(strategy)\n",
        "        ax.set_xlim(0.4, 1.0)\n",
        "        ax.set_ylim(0.4, 1.0)\n",
        "        ax.legend(loc='lower right', fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Overfitting Analysis: Train vs Val AUROC', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    out_path = os.path.join(fig_dir, 'overfitting_analysis.png')\n",
        "    plt.savefig(out_path, dpi=150)\n",
        "    plt.close()\n",
        "    print(f\"  Saved overfitting analysis plot to {out_path}\")"
      ],
      "metadata": {
        "id": "ad71mvLvJauE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading Functions\n",
        "\n",
        "Vectorized with Dynamic Stride to increase positive sample size"
      ],
      "metadata": {
        "id": "NjV2SCC8JeDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hr_series(rec_ecg_rel, base_dir):\n",
        "    rec_path = os.path.join(base_dir, rec_ecg_rel)\n",
        "    header = wfdb.rdheader(rec_path)\n",
        "    brady_ann = wfdb.rdann(rec_path, 'atr')\n",
        "    brady_times = np.array(brady_ann.sample) / header.fs\n",
        "    r_ann = wfdb.rdann(rec_path, 'qrsc')\n",
        "    r_times = np.array(r_ann.sample) / header.fs\n",
        "    RR = np.diff(r_times)\n",
        "    return r_times[1:], 60.0 / RR, brady_times\n",
        "\n",
        "def load_resp_waveform(rec_ecg_rel, base_dir):\n",
        "    dirname, basename = os.path.split(rec_ecg_rel)\n",
        "    infant_prefix = basename.split(\"_\")[0]\n",
        "    resp_path = os.path.join(base_dir, dirname, infant_prefix + \"_resp\")\n",
        "    resp_record = wfdb.rdrecord(resp_path)\n",
        "    return np.arange(len(resp_record.p_signal)) / resp_record.fs, resp_record.p_signal[:, 0]\n",
        "\n",
        "def resample_hr_and_resp(hr_times, HR, t_resp, resp_signal):\n",
        "    HR_clip = np.clip(HR, config.HR_CLIP_MIN, config.HR_CLIP_MAX)\n",
        "    t_start, t_end = max(hr_times[0], t_resp[0]), min(hr_times[-1], t_resp[-1])\n",
        "    t_grid = np.arange(t_start, t_end, 1.0 / config.FS_GRID)\n",
        "    return t_grid, np.interp(t_grid, hr_times, HR_clip), np.interp(t_grid, t_resp, resp_signal)\n",
        "\n",
        "def make_windows(t_grid, hr_grid, resp_grid, brady_times, config, lead_time=None):\n",
        "    \"\"\"\n",
        "    Vectorized window generation with dynamic positive-region sampling & distance return\n",
        "    \"\"\"\n",
        "    if lead_time is None:\n",
        "        lead_time = config.LEAD_TIME\n",
        "\n",
        "    L = int(config.WINDOW_LEN * config.FS_GRID)\n",
        "    step = int(config.DENSE_STRIDE * config.FS_GRID)\n",
        "\n",
        "    horizon_steps = int(config.HORIZON * config.FS_GRID)\n",
        "    gap_steps = int(lead_time * config.FS_GRID)\n",
        "\n",
        "    data = np.stack([hr_grid, resp_grid], axis=0)\n",
        "    windows = sliding_window_view(data, window_shape=L, axis=1)[:, ::step, :]\n",
        "    windows = windows.transpose(1, 0, 2)\n",
        "\n",
        "    n_windows = windows.shape[0]\n",
        "    indices = np.arange(0, n_windows * step, step)\n",
        "    times = t_grid[indices]\n",
        "\n",
        "    pred_starts = times + config.WINDOW_LEN + lead_time\n",
        "    pred_ends   = pred_starts + config.HORIZON\n",
        "\n",
        "    brady_times = np.sort(brady_times)\n",
        "    idx_start = np.searchsorted(brady_times, pred_starts)\n",
        "    idx_end   = np.searchsorted(brady_times, pred_ends)\n",
        "    y = (idx_end > idx_start).astype(np.int64)\n",
        "\n",
        "    valid_mask = (indices + L + gap_steps + horizon_steps) <= len(t_grid)\n",
        "\n",
        "    windows     = windows[valid_mask]\n",
        "    y           = y[valid_mask]\n",
        "    times       = times[valid_mask]\n",
        "    pred_starts = pred_starts[valid_mask]\n",
        "\n",
        "    # Distance to nearest brady event for every window\n",
        "    if len(brady_times) > 0:\n",
        "        b_idx = np.searchsorted(brady_times, pred_starts)\n",
        "        b_idx = np.clip(b_idx, 0, len(brady_times) - 1)\n",
        "\n",
        "        dist_right = np.abs(pred_starts - brady_times[b_idx])\n",
        "        dist_left  = np.abs(\n",
        "            pred_starts - brady_times[np.clip(b_idx - 1, 0, len(brady_times) - 1)]\n",
        "        )\n",
        "        min_dist = np.minimum(dist_left, dist_right)\n",
        "    else:\n",
        "        # No events in this record; treat as \"far away\"\n",
        "        min_dist = np.full_like(pred_starts, fill_value=config.POS_REGION_RADIUS * 2.0, dtype=float)\n",
        "\n",
        "    # DYNAMIC SAMPLING LOGIC\n",
        "    if len(brady_times) > 0:\n",
        "        is_dense_region = min_dist <= config.POS_REGION_RADIUS\n",
        "    else:\n",
        "        is_dense_region = np.zeros(len(times), dtype=bool)\n",
        "\n",
        "    stride_ratio = int(config.STRIDE / config.DENSE_STRIDE)\n",
        "    window_indices = np.arange(len(times))\n",
        "    is_grid_aligned = (window_indices % stride_ratio) == 0\n",
        "\n",
        "    keep_mask = is_dense_region | is_grid_aligned\n",
        "\n",
        "    # Also return min_dist for kept windows\n",
        "    return (\n",
        "        windows[keep_mask].astype(np.float32),\n",
        "        y[keep_mask],\n",
        "        times[keep_mask],\n",
        "        min_dist[keep_mask].astype(np.float32),\n",
        "    )\n",
        "\n",
        "def load_infant(rec_ecg_rel, base_dir):\n",
        "    hr_times, HR, brady_times = load_hr_series(rec_ecg_rel, base_dir)\n",
        "    t_resp, resp_sig = load_resp_waveform(rec_ecg_rel, base_dir)\n",
        "    t_grid, hr_grid, resp_grid = resample_hr_and_resp(hr_times, HR, t_resp, resp_sig)\n",
        "    X, y, times, dist_to_event = make_windows(t_grid, hr_grid, resp_grid, brady_times, config)\n",
        "    sort_idx = np.argsort(times)\n",
        "    return (\n",
        "        X[sort_idx],\n",
        "        y[sort_idx],\n",
        "        times[sort_idx],\n",
        "        dist_to_event[sort_idx],\n",
        "    )"
      ],
      "metadata": {
        "id": "JXk2yQ4zKjmL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "bfsY-eyrKlKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renamed cache file to automatically force rebuild without manual deletion\n",
        "data_cache_path = os.path.join(OUTPUT_DIR, 'data', 'infant_data_cache_time_aware.npz')\n",
        "metadata_path = os.path.join(OUTPUT_DIR, 'data', 'infant_metadata_time_aware.csv')\n",
        "\n",
        "if os.path.exists(data_cache_path) and os.path.exists(metadata_path):\n",
        "    print(\"Loading cached data...\")\n",
        "    cache = np.load(data_cache_path, allow_pickle=True)\n",
        "    infant_data = cache['infant_data'].item()\n",
        "    print(f\"Loaded {len(infant_data)} infants from cache\")\n",
        "else:\n",
        "    if os.path.exists(config.LOCAL_PATH):\n",
        "        hea_files = glob.glob(os.path.join(config.LOCAL_PATH, \"**\", \"*.hea\"), recursive=True)\n",
        "        record_names = [os.path.relpath(os.path.splitext(p)[0], config.LOCAL_PATH) for p in hea_files]\n",
        "        ecg_records = sorted([r for r in record_names if r.endswith(\"_ecg\")])\n",
        "\n",
        "        infant_data = {}\n",
        "        metadata = []\n",
        "\n",
        "        for rec in ecg_records:\n",
        "            X, y, times, dist_to_event = load_infant(rec, config.LOCAL_PATH)\n",
        "            infant_id = os.path.basename(rec).split(\"_\")[0]\n",
        "            infant_data[infant_id] = {\n",
        "                'X': X,\n",
        "                'y': y,\n",
        "                'times': times,\n",
        "                'dist_to_event': dist_to_event,   # NEW\n",
        "            }\n",
        "            metadata.append({'infant_id': infant_id, 'n_windows': len(y), 'n_pos': int(y.sum())})\n",
        "            print(f\"  {infant_id}: {len(y):,} windows (Pos: {y.sum()})\")\n",
        "\n",
        "        np.savez(data_cache_path, infant_data=infant_data)\n",
        "        pd.DataFrame(metadata).to_csv(metadata_path, index=False)\n",
        "    else:\n",
        "        print(\"Data source not found. Please ensure LOCAL_PATH is correct.\")\n",
        "        infant_data = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSxy3vfRKoHd",
        "outputId": "4a9683ae-5457-4dc6-f52d-97b58fc98fb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cached data...\n",
            "Loaded 10 infants from cache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model DEfinitions"
      ],
      "metadata": {
        "id": "SyLqibYFKwf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y, sample_weight: Optional[np.ndarray] = None):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).float()\n",
        "        if sample_weight is not None:\n",
        "            self.w = torch.from_numpy(sample_weight.astype(np.float32))\n",
        "        else:\n",
        "            self.w = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.w is None:\n",
        "            return self.X[idx], self.y[idx]\n",
        "        else:\n",
        "            return self.X[idx], self.y[idx], self.w[idx]\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Linear(hidden_dim, 1)\n",
        "    def forward(self, x):\n",
        "        scores = self.attention(x)\n",
        "        weights = F.softmax(scores, dim=1)\n",
        "        context = torch.sum(weights * x, dim=1)\n",
        "        return context, weights\n",
        "\n",
        "class CNNBiLSTM(nn.Module):\n",
        "    def __init__(self, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(2, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 3, padding=1), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(64, 64, batch_first=True, bidirectional=True)\n",
        "        self.attention = Attention(128)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Sequential(nn.Linear(128, 64), nn.ReLU(), nn.Dropout(dropout), nn.Linear(64, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x).permute(0, 2, 1)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        context, _ = self.attention(lstm_out)\n",
        "        return self.fc(self.dropout(context)).squeeze(1)\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    \"\"\"\n",
        "    Remove extra timesteps introduced by right padding so that\n",
        "    causal convolutions keep the same effective length.\n",
        "    \"\"\"\n",
        "    def __init__(self, chomp_size: int):\n",
        "        super().__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.chomp_size == 0:\n",
        "            return x\n",
        "        return x[:, :, :-self.chomp_size]\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid Temporal Block:\n",
        "      - Dilated causal convs\n",
        "      - BatchNorm for stability\n",
        "      - Residual connection (with 1x1 conv if channels change)\n",
        "      - Dropout for regularization\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: int,\n",
        "        dilation: int,\n",
        "        dropout: float = 0.3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) * dilation  # causal padding\n",
        "\n",
        "        # Conv 1\n",
        "        self.conv1 = nn.Conv1d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            padding=padding,\n",
        "            dilation=dilation,\n",
        "        )\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Conv 2\n",
        "        self.conv2 = nn.Conv1d(\n",
        "            out_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            padding=padding,\n",
        "            dilation=dilation,\n",
        "        )\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "\n",
        "        # Residual path\n",
        "        self.downsample = (\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
        "            if in_channels != out_channels\n",
        "            else None\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.chomp1(out)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.drop1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.chomp2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.drop2(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid TCN classifier:\n",
        "      - Input:  (B, 2, T)\n",
        "      - Output: logits (B,)\n",
        "      - Strategy: Concatenates GAP (state) and Last-Timestep (trajectory)\n",
        "                  to capture both sustained distress and sudden events.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dropout: float = 0.3,\n",
        "        num_channels: tuple = (32, 64, 64, 128, 128),\n",
        "        kernel_size: int = 3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        in_ch = 2\n",
        "\n",
        "        for i, out_ch in enumerate(num_channels):\n",
        "            dilation = 2 ** i\n",
        "            layers.append(\n",
        "                TemporalBlock(\n",
        "                    in_channels=in_ch,\n",
        "                    out_channels=out_ch,\n",
        "                    kernel_size=kernel_size,\n",
        "                    dilation=dilation,\n",
        "                    dropout=dropout\n",
        "                )\n",
        "            )\n",
        "            in_ch = out_ch\n",
        "\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "\n",
        "        # Concat (Mean_Pool, Last_Step\n",
        "        combined_dim = num_channels[-1] * 2\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(combined_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 2, T)\n",
        "        features = self.tcn(x)      # (B, C_last, T)\n",
        "\n",
        "        # 1. Global Average Pooling (The \"State\")\n",
        "        gap = features.mean(dim=2)  # (B, C_last)\n",
        "\n",
        "        # 2. Last Timestep (The \"Trajectory\")\n",
        "        last = features[:, :, -1]   # (B, C_last)\n",
        "\n",
        "        # 3. Concatenate\n",
        "        combined = torch.cat([gap, last], dim=1)  # (B, C_last * 2)\n",
        "\n",
        "        y = self.fc(combined)       # (B, 1)\n",
        "        return y.squeeze(1)\n",
        "\n",
        "\n",
        "class TraditionalML:\n",
        "    def __init__(self, model_type, config):\n",
        "        self.model_type = model_type\n",
        "        self.config = config\n",
        "        self.RANDOM_SEED = RANDOM_SEED\n",
        "        self.history_ = {}\n",
        "\n",
        "        if model_type == 'XGBoost':\n",
        "            # Use 'hist' tree method (speed optimization)\n",
        "            xgb_params = {\n",
        "                'n_estimators': 100,\n",
        "                'scale_pos_weight': 1.0,           # placeholder, overridden in fit()\n",
        "                'eval_metric': ['logloss', 'auc'],\n",
        "                'random_state': self.RANDOM_SEED,\n",
        "                'n_jobs': -1\n",
        "            }\n",
        "\n",
        "            # Use GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                xgb_params['tree_method'] = 'gpu_hist'\n",
        "                xgb_params['predictor'] = 'gpu_predictor'\n",
        "            else:\n",
        "                xgb_params['tree_method'] = 'hist'\n",
        "\n",
        "            self.model = xgb.XGBClassifier(**xgb_params)\n",
        "\n",
        "        elif model_type == 'Random Forest':\n",
        "            self.model = RandomForestClassifier(\n",
        "                n_estimators=200,\n",
        "                max_depth=15,\n",
        "                class_weight='balanced',\n",
        "                random_state=self.RANDOM_SEED,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "        else:  # Logistic Regression\n",
        "            self.model = LogisticRegression(\n",
        "                class_weight='balanced',\n",
        "                max_iter=1000,\n",
        "                random_state=self.RANDOM_SEED,\n",
        "                n_jobs=-1 # sklearn uses this where possible\n",
        "            )\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        self.impute_values_ = None\n",
        "\n",
        "    @property\n",
        "    def feature_names(self):\n",
        "        \"\"\"Returns the list of feature names in the exact order of extraction.\"\"\"\n",
        "        # 1. Basic Stats (10 per signal * 2 signals = 20)\n",
        "        stats = ['Mean', 'Std', 'Min', 'Max', 'P25', 'P50', 'P75',\n",
        "                 'Range', 'DiffMean', 'DiffStd']\n",
        "        names = [f\"HR_{s}\" for s in stats] + [f\"Resp_{s}\" for s in stats]\n",
        "\n",
        "        # 2. Clinical HR (3)\n",
        "        names.extend(['Rapid_Decels', 'Max_Decel_Rate', 'Time_Under_100'])\n",
        "        # 3. Trend (1)\n",
        "        names.append('HR_Slope')\n",
        "        # 4. Coupling (1)\n",
        "        names.append('HR_Resp_Corr')\n",
        "        # 5. Spectral/HRV (3)\n",
        "        names.extend(['LF_Power', 'HF_Power', 'LF_HF_Ratio'])\n",
        "        return names\n",
        "\n",
        "    def get_feature_importance(self):\n",
        "        # return feature importance depending on model type\n",
        "        names = self.feature_names\n",
        "        if self.model_type == 'Logistic Regression':\n",
        "            importances = np.abs(self.model.coef_[0])\n",
        "        elif hasattr(self.model, 'feature_importances_'):\n",
        "            importances = self.model.feature_importances_\n",
        "        else:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        return (\n",
        "            pd.DataFrame({'Feature': names, 'Importance': importances})\n",
        "              .sort_values(by='Importance', ascending=False)\n",
        "        )\n",
        "\n",
        "    def _features(self, X):\n",
        "        \"\"\"\n",
        "        Fully Vectorized Feature Extraction.\n",
        "        (Faster than looping with matrix operations.)\n",
        "        \"\"\"\n",
        "        # X shape: (N, 2, L) -> N windows, 2 signals, L timesteps\n",
        "        hr = X[:, 0, :]    # (N, L)\n",
        "        resp = X[:, 1, :]  # (N, L)\n",
        "\n",
        "        N, L = hr.shape\n",
        "\n",
        "        # Basic Stats (Vectorized)\n",
        "        # Calculate stats for HR & Resp simultaneously\n",
        "\n",
        "        feats = []\n",
        "\n",
        "        for sig in [hr, resp]:\n",
        "            diff = np.diff(sig, axis=1) # (N, L-1)\n",
        "\n",
        "            # Percentiles\n",
        "            p25 = np.percentile(sig, 25, axis=1)\n",
        "            p50 = np.percentile(sig, 50, axis=1)\n",
        "            p75 = np.percentile(sig, 75, axis=1)\n",
        "\n",
        "            feats.extend([\n",
        "                np.mean(sig, axis=1),\n",
        "                np.std(sig, axis=1),\n",
        "                np.min(sig, axis=1),\n",
        "                np.max(sig, axis=1),\n",
        "                p25,\n",
        "                p50,\n",
        "                p75,\n",
        "                sig[:, -1] - sig[:, 0], # Range (End - Start)\n",
        "                np.mean(diff, axis=1),\n",
        "                np.std(diff, axis=1)\n",
        "            ])\n",
        "\n",
        "        # Clinical HR features (Vectorized)\n",
        "        hr_diff = np.diff(hr, axis=1)\n",
        "\n",
        "        feats.extend([\n",
        "            np.sum(hr_diff < -2, axis=1),  # Rapid Decels count\n",
        "            np.min(hr_diff, axis=1),       # Max decel rate (min value of diff)\n",
        "            np.sum(hr < 100, axis=1)       # Time under 100\n",
        "        ])\n",
        "\n",
        "        # Trend: Slope (Vectorized Linear Regression)\n",
        "        # Slope = cov(x, y) / var(x)\n",
        "        # Since x (time) is 0..L-1 for all windows, we can precompute x components\n",
        "        x_axis = np.arange(L)\n",
        "        x_mean = np.mean(x_axis)\n",
        "        x_centered = x_axis - x_mean\n",
        "        denom = np.sum(x_centered ** 2)\n",
        "\n",
        "        # Center HR windows\n",
        "        hr_mean = np.mean(hr, axis=1, keepdims=True)\n",
        "        hr_centered = hr - hr_mean\n",
        "\n",
        "        # Vectorized dot product (numerator of slope formula)\n",
        "        # (N, L) @ (L,) -> (N,)\n",
        "        numer = np.dot(hr_centered, x_centered)\n",
        "        slope = numer / denom\n",
        "        feats.append(slope)\n",
        "\n",
        "        # Coupling: Correlation (Vectorized Pearson)\n",
        "        # Corr = E[(X-Ux)(Y-Uy)] / (Sx * Sy)\n",
        "\n",
        "        # We already have hr_centered. Need resp_centered.\n",
        "        resp_mean = np.mean(resp, axis=1, keepdims=True)\n",
        "        resp_centered = resp - resp_mean\n",
        "\n",
        "        # Covariance numerator\n",
        "        cov_num = np.sum(hr_centered * resp_centered, axis=1)\n",
        "\n",
        "        # Standard deviations (N,)\n",
        "        hr_std = np.std(hr, axis=1)\n",
        "        resp_std = np.std(resp, axis=1)\n",
        "\n",
        "        # Avoid div by zero\n",
        "        denom_corr = (hr_std * resp_std * L)\n",
        "        # Using population std (numpy default), formula matches np.corrcoef logic approx\n",
        "        # Actually, simpler: sum((x-mx)(y-my)) / sqrt(sum((x-mx)^2) * sum((y-my)^2))\n",
        "        denom_corr_geo = np.sqrt(np.sum(hr_centered**2, axis=1) * np.sum(resp_centered**2, axis=1))\n",
        "\n",
        "        corr = np.divide(cov_num, denom_corr_geo, out=np.zeros_like(cov_num), where=denom_corr_geo!=0)\n",
        "        feats.append(corr)\n",
        "\n",
        "        # Spectral / HRV (Vectorized Welch)\n",
        "        # scipy.signal.welch supports axis argument\n",
        "        freqs, Pxx = welch(hr, fs=self.config.FS_GRID, nperseg=L, axis=-1)\n",
        "\n",
        "        # Masks for bands (freqs is 1D array)\n",
        "        lf_mask = (freqs >= 0.04) & (freqs <= 0.15)\n",
        "        hf_mask = (freqs >= 0.15) & (freqs <= 0.4)\n",
        "\n",
        "        # Integrate (Trapezoidal rule) along the frequency axis\n",
        "        # Pxx is (N, n_freqs)\n",
        "\n",
        "        # LF Power\n",
        "        if np.any(lf_mask):\n",
        "            lf = np.trapz(Pxx[:, lf_mask], freqs[lf_mask], axis=1)\n",
        "        else:\n",
        "            lf = np.zeros(N)\n",
        "\n",
        "        # HF Power\n",
        "        if np.any(hf_mask):\n",
        "            hf = np.trapz(Pxx[:, hf_mask], freqs[hf_mask], axis=1)\n",
        "        else:\n",
        "            hf = np.zeros(N)\n",
        "\n",
        "        feats.append(lf)\n",
        "        feats.append(hf)\n",
        "\n",
        "        # Ratio with safe divide\n",
        "        ratio = np.divide(lf, hf + 1e-6, out=np.zeros_like(lf), where=hf > 1e-9)\n",
        "        feats.append(ratio)\n",
        "\n",
        "        # Stack all feature arrays: List of 1D (N,) arrays -> (N, n_features)\n",
        "        return np.column_stack(feats)\n",
        "\n",
        "    def _prepare_data(self, X, is_train=True):\n",
        "        \"\"\"Feature extraction + NaN imputation + scaling.\"\"\"\n",
        "        # This now calls the Vectorized _features\n",
        "        feats = self._features(X)\n",
        "        feats[~np.isfinite(feats)] = np.nan\n",
        "\n",
        "        if is_train:\n",
        "            # Column-wise means for imputation\n",
        "            self.impute_values_ = np.nan_to_num(\n",
        "                np.nanmean(feats, axis=0),\n",
        "                nan=0.0\n",
        "            )\n",
        "\n",
        "        idx_nan = np.isnan(feats)\n",
        "        if np.any(idx_nan):\n",
        "            feats[idx_nan] = np.take(\n",
        "                self.impute_values_,\n",
        "                np.where(idx_nan)[1]\n",
        "            )\n",
        "\n",
        "        if is_train:\n",
        "            return self.scaler.fit_transform(feats)\n",
        "        else:\n",
        "            return self.scaler.transform(feats)\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_val=None,\n",
        "        y_val=None,\n",
        "        subject_id=\"unknown\",\n",
        "        strategy=\"unknown\",\n",
        "        save_history_path=None\n",
        "    ):\n",
        "        feats_train = self._prepare_data(X_train, is_train=True)\n",
        "        feats_val = (\n",
        "            self._prepare_data(X_val, is_train=False)\n",
        "            if X_val is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        history = {}\n",
        "\n",
        "        # XGBoost: dynamic scale_pos_weight per fold\n",
        "        if self.model_type == 'XGBoost':\n",
        "            n_pos = np.sum(y_train == 1)\n",
        "            n_neg = np.sum(y_train == 0)\n",
        "\n",
        "            if n_pos > 0:\n",
        "                spw = n_neg / float(n_pos)\n",
        "            else:\n",
        "                spw = 1.0  # degenerate all-negative case\n",
        "\n",
        "            self.model.set_params(scale_pos_weight=spw)\n",
        "            print(f\"[XGBoost] Using dynamic scale_pos_weight={spw:.3f} for this fold\")\n",
        "\n",
        "            if feats_val is not None:\n",
        "                eval_set = [(feats_train, y_train), (feats_val, y_val)]\n",
        "                self.model.fit(feats_train, y_train, eval_set=eval_set, verbose=False)\n",
        "                results = self.model.evals_result()\n",
        "\n",
        "                # We asked for eval_metric=['logloss','auc'], so 'auc' is available:\n",
        "                #   results['validation_0']['auc'], results['validation_1']['auc']\n",
        "                if 'validation_0' in results and 'auc' in results['validation_0']:\n",
        "                    history['train_auroc'] = results['validation_0']['auc']\n",
        "                    history['val_auroc'] = results['validation_1']['auc']\n",
        "                    history['n_rounds'] = len(history['train_auroc'])\n",
        "                    self.history_ = history\n",
        "            else:\n",
        "                self.model.fit(feats_train, y_train)\n",
        "\n",
        "        elif self.model_type in ['Random Forest', 'Logistic Regression'] and feats_val is not None:\n",
        "            # Learning curve style analysis\n",
        "            rng = np.random.RandomState(self.RANDOM_SEED)\n",
        "            n = len(feats_train)\n",
        "            fracs = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
        "            train_au, val_au, sizes = [], [], []\n",
        "\n",
        "            for frac in fracs:\n",
        "                k = max(50, int(n * frac))\n",
        "                idx = rng.choice(n, size=k, replace=False)\n",
        "                X_sub, y_sub = feats_train[idx], y_train[idx]\n",
        "\n",
        "                if self.model_type == 'Random Forest':\n",
        "                    temp = RandomForestClassifier(\n",
        "                        n_estimators=self.model.n_estimators,\n",
        "                        max_depth=self.model.max_depth,\n",
        "                        class_weight='balanced',\n",
        "                        random_state=self.RANDOM_SEED,\n",
        "                        n_jobs=-1\n",
        "                    )\n",
        "                else:\n",
        "                    temp = LogisticRegression(\n",
        "                        class_weight='balanced',\n",
        "                        max_iter=1000,\n",
        "                        random_state=self.RANDOM_SEED,\n",
        "                        n_jobs=-1\n",
        "                    )\n",
        "\n",
        "                temp.fit(X_sub, y_sub)\n",
        "                try:\n",
        "                    train_au.append(\n",
        "                        roc_auc_score(y_sub, temp.predict_proba(X_sub)[:, 1])\n",
        "                    )\n",
        "                except Exception:\n",
        "                    train_au.append(0.5)\n",
        "\n",
        "                try:\n",
        "                    val_au.append(\n",
        "                        roc_auc_score(y_val, temp.predict_proba(feats_val)[:, 1])\n",
        "                    )\n",
        "                except Exception:\n",
        "                    val_au.append(0.5)\n",
        "\n",
        "                sizes.append(k)\n",
        "\n",
        "            history['train_size'] = sizes\n",
        "            history['train_auroc'] = train_au\n",
        "            history['val_auroc'] = val_au\n",
        "            self.history_ = history\n",
        "            self.model.fit(feats_train, y_train)\n",
        "\n",
        "        else:\n",
        "            # No validation data: just fit\n",
        "            self.model.fit(feats_train, y_train)\n",
        "\n",
        "        # Save history for diagnostics\n",
        "        if save_history_path and self.history_:\n",
        "            np.savez(\n",
        "                save_history_path,\n",
        "                **history,\n",
        "                model_type=self.model_type,\n",
        "                subject_id=subject_id,\n",
        "                strategy=strategy\n",
        "            )\n",
        "\n",
        "        # Return train AUROC\n",
        "        train_probs = self.model.predict_proba(feats_train)[:, 1]\n",
        "        return roc_auc_score(y_train, train_probs)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        feats = self._prepare_data(X, is_train=False)\n",
        "        return self.model.predict_proba(feats)[:, 1]"
      ],
      "metadata": {
        "id": "Lspzf9-dLcp9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loops"
      ],
      "metadata": {
        "id": "TsW1zea_LjwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, probs, threshold=0.5):\n",
        "    \"\"\"Calculates AUROC, AUPRC, and Accuracy for diagnostics.\"\"\"\n",
        "    try:\n",
        "        auroc = roc_auc_score(y_true, probs)\n",
        "    except Exception:\n",
        "        auroc = 0.5\n",
        "    try:\n",
        "        auprc = average_precision_score(y_true, probs)\n",
        "    except Exception:\n",
        "        auprc = 0.0\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    return auroc, auprc, acc\n",
        "\n",
        "def standardize(X_train, X_val, X_test):\n",
        "    mean, std = X_train.mean(axis=(0, 2), keepdims=True), X_train.std(axis=(0, 2), keepdims=True) + 1e-8\n",
        "    return (X_train - mean) / std, (X_val - mean) / std, (X_test - mean) / std\n",
        "\n",
        "def make_weighted_sampler_with_target(y_np: np.ndarray, target_pos_ratio: float) -> WeightedRandomSampler:\n",
        "    \"\"\"\n",
        "    Create a WeightedRandomSampler that aims for a given positive fraction\n",
        "    in the sampled batches.\n",
        "\n",
        "    target_pos_ratio: desired positive fraction in (0,1).\n",
        "    For heavy imbalance, values like 0.2–0.3 are typically 'mild'.\n",
        "    \"\"\"\n",
        "    y_t = torch.from_numpy(y_np.astype(np.int64))\n",
        "    n_pos = int((y_t == 1).sum())\n",
        "    n_neg = int((y_t == 0).sum())\n",
        "    N = n_pos + n_neg\n",
        "\n",
        "    # Edge cases: if only one class exists, fall back to uniform sampling\n",
        "    if n_pos == 0 or n_neg == 0 or N == 0:\n",
        "        sample_weights = torch.ones_like(y_t, dtype=torch.float32)\n",
        "        return WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "    p_pos = n_pos / N\n",
        "    p_neg = n_neg / N\n",
        "\n",
        "    eps = 1e-6\n",
        "    t_pos = float(target_pos_ratio)\n",
        "    t_pos = max(min(t_pos, 0.95), 0.05)  # keep within reasonable bounds\n",
        "    t_neg = 1.0 - t_pos\n",
        "\n",
        "    # Class weights that push the effective sampling distribution toward t_pos / t_neg\n",
        "    w_pos_raw = t_pos / (p_pos + eps)\n",
        "    w_neg_raw = t_neg / (p_neg + eps)\n",
        "\n",
        "    # Normalize so average weight is ~1.0 (not strictly necessary, but tidy)\n",
        "    mean_w = 0.5 * (w_pos_raw + w_neg_raw)\n",
        "    w_pos = w_pos_raw / (mean_w + eps)\n",
        "    w_neg = w_neg_raw / (mean_w + eps)\n",
        "\n",
        "    weights_per_class = torch.tensor([w_neg, w_pos], dtype=torch.float32)\n",
        "    sample_weights = weights_per_class[y_t]\n",
        "\n",
        "    return WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "def build_sample_weights(\n",
        "    y_np: np.ndarray,\n",
        "    dist_np: np.ndarray,\n",
        "    pos_weight_scalar: float,\n",
        "    radius: Optional[float] = None,\n",
        "    min_fp_weight: Optional[float] = None,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build per-sample weights combining:\n",
        "      - class cost-sensitivity (pos_weight_scalar for positives)\n",
        "      - time-aware FP de-emphasis for negatives near events.\n",
        "\n",
        "    y_np: labels {0,1}, shape (N,)\n",
        "    dist_np: distance to nearest event in seconds, shape (N,)\n",
        "    pos_weight_scalar: class weight for positives\n",
        "    radius: within this many seconds, FP penalty ramps from min_fp_weight -> 1\n",
        "    min_fp_weight: FP weight at distance=0 (0-1; e.g. 0.2)\n",
        "    \"\"\"\n",
        "    if radius is None:\n",
        "        radius = config.POS_REGION_RADIUS\n",
        "    if min_fp_weight is None:\n",
        "        min_fp_weight = config.MIN_FP_WEIGHT\n",
        "\n",
        "    y = y_np.astype(np.float32)\n",
        "    d = dist_np.astype(np.float32)\n",
        "\n",
        "    # Clip distances; beyond radius, we treat all as \"far\"\n",
        "    d_clipped = np.minimum(d, radius)\n",
        "    normalized = d_clipped / (radius + 1e-6)\n",
        "\n",
        "    # For negatives: linear ramp [0, radius] -> [min_fp_weight, 1.0]\n",
        "    neg_time_factor = min_fp_weight + (1.0 - min_fp_weight) * normalized\n",
        "\n",
        "    # Base class weights: positives get pos_weight_scalar, negatives get 1.0\n",
        "    w_class = np.where(y == 1.0, pos_weight_scalar, 1.0)\n",
        "\n",
        "    # Time factor only affects negatives\n",
        "    w_time = np.where(y == 1.0, 1.0, neg_time_factor)\n",
        "\n",
        "    w = w_class * w_time\n",
        "    return w.astype(np.float32)\n",
        "\n",
        "\n",
        "def train_deep_model(\n",
        "    model_name,\n",
        "    X_train, y_train, dist_train,\n",
        "    X_val,   y_val,\n",
        "    device,\n",
        "    save_path=None,\n",
        "    history_path=None,\n",
        "    subject_id=\"unknown\",\n",
        "    strategy=\"unknown\",\n",
        "):\n",
        "    # Build the chosen architecture\n",
        "    if model_name == 'CNN-BiLSTM':\n",
        "        model = CNNBiLSTM(config.DROPOUT).to(device)\n",
        "    elif model_name == 'TCN':\n",
        "        # use_gap=True because GAP outperformed last-timestep in the quick diagnostic\n",
        "        model = TCNModel(dropout=config.DROPOUT).to(device)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown deep model '{model_name}'\")\n",
        "\n",
        "    # Persistent Workers + Pin Memory + Seeded Worker\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(RANDOM_SEED)\n",
        "\n",
        "    # --- class imbalance weight (scalar) ---\n",
        "    n_pos = y_train.sum()\n",
        "    n_neg = len(y_train) - y_train.sum()\n",
        "    pos_weight_scalar = float(min(n_neg / (n_pos + 1e-6), config.MAX_POS_WEIGHT))\n",
        "\n",
        "    # --- build time-aware, class-weighted per-sample weights ---\n",
        "    sample_w_train = build_sample_weights(\n",
        "        y_np=y_train,\n",
        "        dist_np=dist_train,\n",
        "        pos_weight_scalar=pos_weight_scalar,\n",
        "        radius=config.POS_REGION_RADIUS,\n",
        "        min_fp_weight=config.MIN_FP_WEIGHT,\n",
        "    )\n",
        "\n",
        "    # dataset + WeightedRandomSampler for training\n",
        "    train_dataset = TimeSeriesDataset(X_train, y_train, sample_weight=sample_w_train)\n",
        "\n",
        "    sampler = make_weighted_sampler_with_target(\n",
        "        y_np=y_train,\n",
        "        target_pos_ratio=config.TARGET_POSITIVE_RATIO\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        sampler=sampler,          # use sampler\n",
        "        shuffle=False,            # must be False when sampler is set\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        TimeSeriesDataset(X_val, y_val),\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        num_workers=config.NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    # Per-sample BCE; we'll apply weights manually\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        weight_decay=config.WEIGHT_DECAY\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='max',\n",
        "        factor=0.5,\n",
        "        patience=3\n",
        "    )\n",
        "\n",
        "    # Initialize GradScaler for Mixed Precision Training (speed optimzation)\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    best_auroc = -1\n",
        "    best_state = None\n",
        "    patience_ctr = 0\n",
        "\n",
        "    # Tracking Accuracy for Plots\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_auroc': [], 'val_auroc': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    print(f\"{'Epoch':^5} | {'Tr Loss':^8} | {'Va Loss':^8} | {'Tr AUC':^8} | {'Va AUC':^8} | {'Status'}\")\n",
        "    print(\"-\" * 65)\n",
        "\n",
        "    for epoch in range(config.N_EPOCHS):\n",
        "        model.train()\n",
        "        train_losses, train_probs, train_labels = [], [], []\n",
        "\n",
        "        for batch in train_loader:\n",
        "            # batch may be (X, y, w) or (X, y)\n",
        "            if len(batch) == 3:\n",
        "                X_b, y_b, w_b = batch\n",
        "                w_b = w_b.to(device, non_blocking=True)\n",
        "            else:\n",
        "                X_b, y_b = batch\n",
        "                w_b = None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Autocast for Mixed Precision (for speed optimization)\n",
        "            with amp.autocast():\n",
        "                logits = model(X_b.to(device, non_blocking=True))\n",
        "                y_b = y_b.to(device, non_blocking=True)\n",
        "                per_sample_loss = criterion(logits, y_b)  # shape (B,)\n",
        "\n",
        "                if w_b is not None:\n",
        "                    loss = (per_sample_loss * w_b).sum() / (w_b.sum() + 1e-6)\n",
        "                else:\n",
        "                    loss = per_sample_loss.mean()\n",
        "\n",
        "            # Scaled backward pass (Speed optimization)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer) # Unscale for clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.GRAD_CLIP)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            train_probs.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
        "            train_labels.append(y_b.detach().cpu().numpy())\n",
        "\n",
        "        model.eval()\n",
        "        val_losses, val_probs = [], []\n",
        "        with torch.no_grad():\n",
        "            for X_b, y_b in val_loader:\n",
        "                # AMP is beneficial even in eval for memory/speed on some GPUs\n",
        "                with amp.autocast():\n",
        "                    logits = model(X_b.to(device, non_blocking=True))\n",
        "                    y_b = y_b.to(device, non_blocking=True)\n",
        "                    per_sample_loss = criterion(logits, y_b)\n",
        "\n",
        "                val_losses.append(per_sample_loss.mean().item())\n",
        "                val_probs.append(torch.sigmoid(logits).float().cpu().numpy()) # Cast back to float for numpy\n",
        "\n",
        "        avg_tr_loss = np.mean(train_losses)\n",
        "        avg_va_loss = np.mean(val_losses)\n",
        "\n",
        "        # Compute all metrics (Accuracy added for plots)\n",
        "        tr_auc, _, tr_acc = compute_metrics(np.concatenate(train_labels), np.concatenate(train_probs))\n",
        "        va_auc, _, va_acc = compute_metrics(y_val, np.concatenate(val_probs))\n",
        "\n",
        "        history['train_loss'].append(avg_tr_loss); history['val_loss'].append(avg_va_loss)\n",
        "        history['train_auroc'].append(tr_auc); history['val_auroc'].append(va_auc)\n",
        "        history['train_acc'].append(tr_acc); history['val_acc'].append(va_acc)\n",
        "\n",
        "        scheduler.step(va_auc)\n",
        "\n",
        "        status = \"\"\n",
        "        if va_auc > best_auroc:\n",
        "            best_auroc = va_auc\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            patience_ctr = 0; status = \"(*)\"\n",
        "        else:\n",
        "            patience_ctr += 1\n",
        "            if patience_ctr >= config.PATIENCE: status = \"STOP\"\n",
        "\n",
        "        print(f\"{epoch+1:^5} | {avg_tr_loss:^8.4f} | {avg_va_loss:^8.4f} | {tr_auc:^8.4f} | {va_auc:^8.4f} | {status}\")\n",
        "        if status == \"STOP\": break\n",
        "\n",
        "    if best_state:\n",
        "        model.load_state_dict(best_state)\n",
        "        if save_path: torch.save({'state_dict': best_state, 'val_auroc': best_auroc}, save_path)\n",
        "\n",
        "    if history_path:\n",
        "        np.savez(history_path, **history, model_type=model_name, subject_id=subject_id, strategy=strategy)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def compute_clinical_metrics(y_true, probs):\n",
        "    if len(np.unique(y_true)) < 2: return {}\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, probs)\n",
        "    specificity = 1 - fpr\n",
        "    results = {}\n",
        "    for target_spec in [0.90, 0.95]:\n",
        "        idx = np.argmin(np.abs(specificity - target_spec))\n",
        "        results[f'sens_at_{int(target_spec*100)}spec'] = tpr[idx]\n",
        "        results[f'threshold_at_{int(target_spec*100)}spec'] = thresholds[idx]\n",
        "    return results\n",
        "\n",
        "def evaluate(model, X_test, y_test, device, is_deep=True):\n",
        "    if is_deep:\n",
        "        model.eval()\n",
        "        loader = DataLoader(TimeSeriesDataset(X_test, y_test), batch_size=config.BATCH_SIZE)\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for X_b, _ in loader:\n",
        "                # AMP in inference\n",
        "                with amp.autocast():\n",
        "                     out = model(X_b.to(device))\n",
        "                probs.append(torch.sigmoid(out).float().cpu().numpy())\n",
        "        probs = np.concatenate(probs)\n",
        "    else:\n",
        "        probs = model.predict_proba(X_test)\n",
        "\n",
        "    auroc, auprc, acc = compute_metrics(y_test, probs)\n",
        "\n",
        "    clinical_res = compute_clinical_metrics(y_test, probs)\n",
        "\n",
        "    results = {\n",
        "        'auroc': auroc,\n",
        "        'auprc': auprc,\n",
        "        'accuracy': acc,\n",
        "        'n_test': len(y_test),\n",
        "        'n_pos': int(y_test.sum()),\n",
        "        'pos_rate': float(y_test.mean())\n",
        "    }\n",
        "\n",
        "    results.update(clinical_res)\n",
        "\n",
        "    return results, probs\n",
        "\n",
        "def train_and_evaluate(\n",
        "    model_name,\n",
        "    X_train, y_train,\n",
        "    X_val,   y_val,\n",
        "    X_test,  y_test,\n",
        "    device,\n",
        "    save_path=None,\n",
        "    subject_id=\"unknown\",\n",
        "    strategy=\"unknown\",\n",
        "    dist_train=None,\n",
        "):\n",
        "\n",
        "    if model_name in ['CNN-BiLSTM', 'TCN']:\n",
        "        history_path = save_path.replace('.pth', '_history.npz') if save_path else None\n",
        "        model, history = train_deep_model(\n",
        "            model_name,\n",
        "            X_train, y_train, dist_train,\n",
        "            X_val,   y_val,\n",
        "            device,\n",
        "            save_path,\n",
        "            history_path,\n",
        "            subject_id,\n",
        "            strategy,\n",
        "        )\n",
        "\n",
        "        plot_dir = os.path.join(OUTPUT_DIR, 'figures', 'learning_curves')\n",
        "        diag_results = plot_learning_curves(history, model_name, subject_id, plot_dir)\n",
        "\n",
        "        # store final train/val AUROC in results dict\n",
        "        final_train_auroc = history['train_auroc'][-1]\n",
        "        final_val_auroc   = history['val_auroc'][-1]\n",
        "\n",
        "        # Evaluate on test\n",
        "        results, probs = evaluate(model, X_test, y_test, device, is_deep=True)\n",
        "\n",
        "        # Add diagnostics & generalization info\n",
        "        results.update(diag_results)\n",
        "        results['train_auroc'] = final_train_auroc\n",
        "        results['val_auroc']   = final_val_auroc\n",
        "        results['train_val_auroc_gap'] = final_train_auroc - final_val_auroc\n",
        "\n",
        "        del model; torch.cuda.empty_cache()\n",
        "\n",
        "    else:\n",
        "        model = TraditionalML(model_name, config)\n",
        "        history_dir = os.path.join(OUTPUT_DIR, strategy.lower(), 'models')\n",
        "        os.makedirs(history_dir, exist_ok=True)\n",
        "        hist_path = os.path.join(history_dir, f\"{model_name.lower().replace(' ', '_')}_{subject_id}_history.npz\")\n",
        "\n",
        "        # Fit model\n",
        "        model.fit(X_train, y_train, X_val, y_val, subject_id, strategy, hist_path)\n",
        "\n",
        "        # Plot traditional learning curves if available\n",
        "        if model.history_:\n",
        "            plot_dir = os.path.join(OUTPUT_DIR, 'figures', 'learning_curves_traditional')\n",
        "            plot_traditional_learning_curves(model.history_, model_name, subject_id, strategy, plot_dir)\n",
        "\n",
        "        # compute train & val AUROC for overfitting analysis\n",
        "        train_probs = model.predict_proba(X_train)\n",
        "        val_probs   = model.predict_proba(X_val)\n",
        "        train_auroc, _, _ = compute_metrics(y_train, train_probs)\n",
        "        val_auroc,   _, _ = compute_metrics(y_val,   val_probs)\n",
        "\n",
        "        # Test evaluation\n",
        "        results, probs = evaluate(model, X_test, y_test, device, is_deep=False)\n",
        "\n",
        "        # Add train/val generalization info\n",
        "        results['train_auroc'] = train_auroc\n",
        "        results['val_auroc']   = val_auroc\n",
        "        results['train_val_auroc_gap'] = train_auroc - val_auroc\n",
        "\n",
        "        if model_name == 'XGBoost':\n",
        "            results['xgb_scale_pos_weight'] = model.model.get_params()['scale_pos_weight']\n",
        "\n",
        "    return results, probs"
      ],
      "metadata": {
        "id": "3JQVj5v0LvFG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run All Strategies"
      ],
      "metadata": {
        "id": "vkyPRvMmLwtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_strategies():\n",
        "    all_infants = sorted(infant_data.keys())\n",
        "    all_results = []\n",
        "\n",
        "    # STRATEGY 1: LOSO\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\nSTRATEGY 1: LOSO\\n\" + \"=\"*50)\n",
        "    for fold_idx, test_infant in enumerate(all_infants):\n",
        "        for model_name in config.MODELS:\n",
        "            task_id = f\"loso_{test_infant}_{model_name}\"\n",
        "            if tracker.is_completed(task_id): continue\n",
        "\n",
        "            print(f\"Running {task_id}...\")\n",
        "            set_seed(RANDOM_SEED + fold_idx)\n",
        "\n",
        "            try:\n",
        "                train_infants = [inf for inf in all_infants if inf != test_infant]\n",
        "                val_inf = train_infants[-1]\n",
        "                train_infants = train_infants[:-1]\n",
        "\n",
        "                X_train = np.concatenate([infant_data[inf]['X'] for inf in train_infants])\n",
        "                y_train = np.concatenate([infant_data[inf]['y'] for inf in train_infants])\n",
        "                d_train = np.concatenate([infant_data[inf]['dist_to_event'] for inf in train_infants])  # NEW\n",
        "\n",
        "                X_val, y_val = infant_data[val_inf]['X'], infant_data[val_inf]['y']\n",
        "                X_test, y_test = infant_data[test_infant]['X'], infant_data[test_infant]['y']\n",
        "\n",
        "                X_train, X_val, X_test = standardize(X_train, X_val, X_test)\n",
        "\n",
        "                model_path = os.path.join(\n",
        "                    OUTPUT_DIR, 'loso', 'models',\n",
        "                    f'{model_name.lower().replace(\" \", \"_\")}_{test_infant}.pth'\n",
        "                )\n",
        "\n",
        "                results, probs = train_and_evaluate(\n",
        "                    model_name,\n",
        "                    X_train, y_train,\n",
        "                    X_val,   y_val,\n",
        "                    X_test,  y_test,\n",
        "                    device,\n",
        "                    save_path=model_path,\n",
        "                    subject_id=test_infant,\n",
        "                    strategy='LOSO',\n",
        "                    dist_train=d_train,\n",
        "                )\n",
        "\n",
        "                results.update({'strategy': 'LOSO', 'model': model_name, 'test_infant': test_infant})\n",
        "                np.savez(os.path.join(OUTPUT_DIR, 'loso', 'predictions', f'{task_id}.npz'), probs=probs, labels=y_test, result=results)\n",
        "                all_results.append(results); tracker.mark_completed(task_id)\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\"); tracker.mark_failed(task_id, str(e))\n",
        "\n",
        "    # STRATEGY 2: TEMPORAL\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\nSTRATEGY 2: TEMPORAL\\n\" + \"=\"*50)\n",
        "    for i, infant_id in enumerate(all_infants):\n",
        "        for model_name in config.MODELS:\n",
        "            task_id = f\"temporal_{infant_id}_{model_name}\"\n",
        "            if tracker.is_completed(task_id): continue\n",
        "\n",
        "            print(f\"Running {task_id}...\")\n",
        "            set_seed(RANDOM_SEED + i)\n",
        "\n",
        "            try:\n",
        "                data = infant_data[infant_id]\n",
        "                n = len(data['y'])\n",
        "\n",
        "                # Use DENSE_STRIDE to calculate the buffer size.\n",
        "                # Because the dataset now contains mixed strides (2s and 10s),\n",
        "                # calculating the buffer using the smallest stride (2s) ensures we skip enough indices\n",
        "                # to guarantee the required time separation, preventing leakage.\n",
        "                buf = int(np.ceil((config.WINDOW_LEN + config.HORIZON) / config.DENSE_STRIDE))\n",
        "\n",
        "                tr_end = int(n * config.TEMPORAL_TRAIN_RATIO)\n",
        "                val_start, val_end = tr_end + buf, int(n * (config.TEMPORAL_TRAIN_RATIO + config.TEMPORAL_VAL_RATIO))\n",
        "                test_start = val_end + buf\n",
        "\n",
        "                if val_start >= val_end or test_start >= n: tracker.mark_completed(task_id); continue\n",
        "\n",
        "                X_train, y_train = data['X'][:tr_end], data['y'][:tr_end]\n",
        "                d_train = data['dist_to_event'][:tr_end]                        # NEW\n",
        "\n",
        "                X_val, y_val = data['X'][val_start:val_end], data['y'][val_start:val_end]\n",
        "                X_test, y_test = data['X'][test_start:], data['y'][test_start:]\n",
        "\n",
        "                if len(y_test) < 50 or y_train.sum() < 5:\n",
        "                    tracker.mark_completed(task_id)\n",
        "                    continue\n",
        "\n",
        "                X_train, X_val, X_test = standardize(X_train, X_val, X_test)\n",
        "\n",
        "                model_path = os.path.join(\n",
        "                    OUTPUT_DIR, 'temporal', 'models',\n",
        "                    f'{model_name.lower().replace(\" \", \"_\")}_{infant_id}.pth'\n",
        "                )\n",
        "\n",
        "                results, probs = train_and_evaluate(\n",
        "                    model_name,\n",
        "                    X_train, y_train,\n",
        "                    X_val,   y_val,\n",
        "                    X_test,  y_test,\n",
        "                    device,\n",
        "                    save_path=model_path,\n",
        "                    subject_id=infant_id,\n",
        "                    strategy='Temporal',\n",
        "                    dist_train=d_train,\n",
        "                )\n",
        "\n",
        "                results.update({'strategy': 'Temporal', 'model': model_name, 'test_infant': infant_id})\n",
        "                np.savez(os.path.join(OUTPUT_DIR, 'temporal', 'predictions', f'{task_id}.npz'), probs=probs, labels=y_test, result=results)\n",
        "                all_results.append(results); tracker.mark_completed(task_id)\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\"); tracker.mark_failed(task_id, str(e))\n",
        "\n",
        "    # STRATEGY 3: HYBRID\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\nSTRATEGY 3: HYBRID\\n\" + \"=\"*50)\n",
        "    for fold_idx, test_infant in enumerate(all_infants):\n",
        "        for model_name in config.MODELS:\n",
        "            task_id = f\"hybrid_{test_infant}_{model_name}\"\n",
        "            if tracker.is_completed(task_id):\n",
        "                continue\n",
        "\n",
        "            print(f\"Running {task_id}...\")\n",
        "            set_seed(RANDOM_SEED + fold_idx)\n",
        "\n",
        "            try:\n",
        "                # 1) Build training data from ALL OTHER infants\n",
        "                other_infants = [inf for inf in all_infants if inf != test_infant]\n",
        "\n",
        "                X_others = np.concatenate(\n",
        "                    [infant_data[inf]['X'] for inf in other_infants]\n",
        "                )\n",
        "                y_others = np.concatenate(\n",
        "                    [infant_data[inf]['y'] for inf in other_infants]\n",
        "                )\n",
        "                d_others = np.concatenate(\n",
        "                    [infant_data[inf]['dist_to_event'] for inf in other_infants]\n",
        "                )\n",
        "\n",
        "                # 2) Temporal split WITHIN the TARGET infant:\n",
        "                # early part: warm-up training\n",
        "                # mid part: validation\n",
        "                # late part: test\n",
        "                test_data = infant_data[test_infant]\n",
        "                n = len(test_data['y'])\n",
        "\n",
        "                # Use DENSE_STRIDE to define a time buffer\n",
        "                # I used LLMs for this to help ensure no leakage\n",
        "                buf = int(\n",
        "                    np.ceil((config.WINDOW_LEN + config.HORIZON) /\n",
        "                            config.DENSE_STRIDE)\n",
        "                )\n",
        "\n",
        "                # Early chunk used as warm-up for training\n",
        "                warmup_end = int(n * config.HYBRID_WARMUP_RATIO)\n",
        "\n",
        "                # Validation starts AFTER a buffer from warmup\n",
        "                val_start = warmup_end + buf\n",
        "\n",
        "                # Use TEMPORAL_VAL_RATIO to define validation size\n",
        "                val_end = int(\n",
        "                    n * (config.HYBRID_WARMUP_RATIO + config.TEMPORAL_VAL_RATIO)\n",
        "                )\n",
        "\n",
        "                # Test starts AFTER another buffer\n",
        "                test_start = val_end + buf\n",
        "\n",
        "                # 3) Sanity checks: make sure these splits are valid\n",
        "                if val_start >= val_end or test_start >= n:\n",
        "                    # Not enough space for val/test with buffers – skip\n",
        "                    tracker.mark_completed(task_id)\n",
        "                    continue\n",
        "\n",
        "                # Ensure we have enough samples for stable metrics\n",
        "                if len(test_data['y'][val_start:val_end]) < 30 or \\\n",
        "                   len(test_data['y'][test_start:]) < 50:\n",
        "                    tracker.mark_completed(task_id)\n",
        "                    continue\n",
        "\n",
        "                # 4) Build final TRAIN / VAL / TEST sets\n",
        "                # TRAIN = all other infants + warm-up portion of target infant\n",
        "                X_train = np.concatenate([\n",
        "                    X_others,\n",
        "                    test_data['X'][:warmup_end]\n",
        "                ])\n",
        "                y_train = np.concatenate([\n",
        "                    y_others,\n",
        "                    test_data['y'][:warmup_end]\n",
        "                ])\n",
        "                d_train = np.concatenate([\n",
        "                    d_others,\n",
        "                    test_data['dist_to_event'][:warmup_end]\n",
        "                ])\n",
        "\n",
        "                # VALIDATION = mid chunk of target infant (non-training data)\n",
        "                X_val = test_data['X'][val_start:val_end]\n",
        "                y_val = test_data['y'][val_start:val_end]\n",
        "\n",
        "                # TEST = late chunk of target infant (completely unseen)\n",
        "                X_test = test_data['X'][test_start:]\n",
        "                y_test = test_data['y'][test_start:]\n",
        "\n",
        "                # Standardize using TRAIN stats only\n",
        "                X_train, X_val, X_test = standardize(X_train, X_val, X_test)\n",
        "\n",
        "                model_path = os.path.join(\n",
        "                    OUTPUT_DIR, 'hybrid', 'models',\n",
        "                    f'{model_name.lower().replace(\" \", \"_\")}_{test_infant}.pth'\n",
        "                )\n",
        "\n",
        "                # 5) Train & evaluate\n",
        "                results, probs = train_and_evaluate(\n",
        "                    model_name,\n",
        "                    X_train, y_train,\n",
        "                    X_val,   y_val,\n",
        "                    X_test,  y_test,\n",
        "                    device,\n",
        "                    save_path=model_path,\n",
        "                    subject_id=test_infant,\n",
        "                    strategy='Hybrid',\n",
        "                    dist_train=d_train,  # time-aware weighting\n",
        "                )\n",
        "\n",
        "                results.update({\n",
        "                    'strategy': 'Hybrid',\n",
        "                    'model': model_name,\n",
        "                    'test_infant': test_infant\n",
        "                })\n",
        "\n",
        "                np.savez(\n",
        "                    os.path.join(\n",
        "                        OUTPUT_DIR, 'hybrid', 'predictions', f'{task_id}.npz'\n",
        "                    ),\n",
        "                    probs=probs,\n",
        "                    labels=y_test,\n",
        "                    result=results\n",
        "                )\n",
        "\n",
        "                all_results.append(results)\n",
        "                tracker.mark_completed(task_id)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "                tracker.mark_failed(task_id, str(e))\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "bxyrgmakMH7i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution & Aggregation"
      ],
      "metadata": {
        "id": "c_K5k-EoMMcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MvjvmYuqb9w",
        "outputId": "76615078-e48a-412c-d78e-4229b0275b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "STRATEGY 1: LOSO\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "STRATEGY 2: TEMPORAL\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "STRATEGY 3: HYBRID\n",
            "==================================================\n",
            "\n",
            "Completed in 0.0 minutes.\n",
            "DIAGNOSTICS\n",
            "\n",
            "Deep Model Fit Summary:\n",
            "Strategy  Fit_Label          \n",
            "Hybrid    Likely overfitting      9\n",
            "          Reasonable fit         11\n",
            "Loso      Likely overfitting      4\n",
            "          Likely underfitting     4\n",
            "          Reasonable fit         12\n",
            "Temporal  Likely overfitting     12\n",
            "          Reasonable fit          8\n",
            "Name: Subject_ID, dtype: int64\n",
            "\n",
            "Traditional Model Fit Summary:\n",
            "Strategy  Model                Fit_Label          \n",
            "Hybrid    Logistic Regression  Likely overfitting      2\n",
            "                               Likely underfitting     5\n",
            "                               Reasonable fit          3\n",
            "          Random Forest        Likely overfitting     10\n",
            "          XGBoost              Likely overfitting      5\n",
            "                               Reasonable fit          5\n",
            "Loso      Logistic Regression  Likely overfitting      1\n",
            "                               Likely underfitting     9\n",
            "          Random Forest        Likely overfitting     10\n",
            "          XGBoost              Likely overfitting     10\n",
            "Temporal  Logistic Regression  Likely overfitting      3\n",
            "                               Likely underfitting     1\n",
            "                               Reasonable fit          6\n",
            "          Random Forest        Likely overfitting     10\n",
            "          XGBoost              Likely overfitting     10\n",
            "Name: Subject_ID, dtype: int64\n",
            "\n",
            "Generating aggregate learning curves...\n",
            "  Saved aggregate curves for LOSO to /content/drive/MyDrive/capstone_results/Merged_Optimized_Diagnostics/figures/aggregate/aggregate_loso_curves.png\n",
            "  Saved aggregate curves for TEMPORAL to /content/drive/MyDrive/capstone_results/Merged_Optimized_Diagnostics/figures/aggregate/aggregate_temporal_curves.png\n",
            "  Saved aggregate curves for HYBRID to /content/drive/MyDrive/capstone_results/Merged_Optimized_Diagnostics/figures/aggregate/aggregate_hybrid_curves.png\n",
            "\n",
            "======================================================================\n",
            "STATISTICAL SIGNIFICANCE TESTING (PAIRED)\n",
            "======================================================================\n",
            "\n",
            "CNN-BiLSTM:\n",
            "\n",
            "TCN:\n",
            "\n",
            "XGBoost:\n",
            "  LOSO vs Hybrid (n=1): p=1.0000 \n",
            "    Mean Diff: 0.0176\n",
            "  LOSO vs Temporal (n=1): p=1.0000 \n",
            "\n",
            "Random Forest:\n",
            "  LOSO vs Hybrid (n=2): p=1.0000 \n",
            "    Mean Diff: 0.0059\n",
            "  LOSO vs Temporal (n=2): p=1.0000 \n",
            "\n",
            "Logistic Regression:\n",
            "  LOSO vs Hybrid (n=2): p=0.5000 \n",
            "    Mean Diff: -0.0156\n",
            "  LOSO vs Temporal (n=2): p=1.0000 \n",
            "\n",
            "Generating overfitting analysis plot...\n",
            "  Saved overfitting analysis plot to /content/drive/MyDrive/capstone_results/Merged_Optimized_Diagnostics/figures/overfitting_analysis.png\n",
            "Execution completed.\n"
          ]
        }
      ],
      "source": [
        "def generate_diagnostics(output_dir):\n",
        "    print(\"DIAGNOSTICS\")\n",
        "\n",
        "    history_rows = []\n",
        "    trad_rows = []\n",
        "\n",
        "    for strategy_name in ['loso', 'temporal', 'hybrid']:\n",
        "        models_dir = os.path.join(output_dir, strategy_name, 'models')\n",
        "        if not os.path.exists(models_dir): continue\n",
        "\n",
        "        for fname in os.listdir(models_dir):\n",
        "            if not fname.endswith('_history.npz'): continue\n",
        "\n",
        "            history_path = os.path.join(models_dir, fname)\n",
        "            try:\n",
        "                hist = np.load(history_path, allow_pickle=True)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            # Metadata extraction\n",
        "            model_type = str(hist['model_type']) if 'model_type' in hist else 'CNN-BiLSTM'\n",
        "            subject_id = str(hist['subject_id']) if 'subject_id' in hist else fname.split('_')[-2]\n",
        "\n",
        "            # CNN Diagnostics\n",
        "            if model_type in ['CNN-BiLSTM', 'TCN'] and 'train_loss' in hist:\n",
        "                train_loss, val_loss = hist['train_loss'], hist['val_loss']\n",
        "                train_auroc, val_auroc = hist['train_auroc'], hist['val_auroc']\n",
        "                best_idx = int(np.argmax(val_auroc))\n",
        "\n",
        "                row = {\n",
        "                    'Strategy': strategy_name.capitalize(), 'Model': model_type, 'Subject_ID': subject_id,\n",
        "                    'Best_Epoch': best_idx + 1,\n",
        "                    'Train_Loss_Best': float(train_loss[best_idx]), 'Val_Loss_Best': float(val_loss[best_idx]),\n",
        "                    'Train_AUROC_Best': float(train_auroc[best_idx]), 'Val_AUROC_Best': float(val_auroc[best_idx]),\n",
        "                    'Loss_Gap': float(val_loss[best_idx] - train_loss[best_idx]),\n",
        "                    'AUROC_Gap': float(train_auroc[best_idx] - val_auroc[best_idx])\n",
        "                }\n",
        "                history_rows.append(row)\n",
        "\n",
        "            # Traditional Diagnostics\n",
        "            else:\n",
        "                if 'n_rounds' in hist: # XGBoost\n",
        "                    val_auroc, train_auroc = hist['val_auroc'], hist['train_auroc']\n",
        "                    best_idx = int(np.argmax(val_auroc))\n",
        "                    row = {\n",
        "                        'Strategy': strategy_name.capitalize(), 'Model': model_type, 'Subject_ID': subject_id,\n",
        "                        'Best_Iter': best_idx + 1,\n",
        "                        'Train_AUROC_Best': float(train_auroc[best_idx]), 'Val_AUROC_Best': float(val_auroc[best_idx]),\n",
        "                        'AUROC_Gap': float(train_auroc[best_idx] - val_auroc[best_idx])\n",
        "                    }\n",
        "                    trad_rows.append(row)\n",
        "                elif 'train_size' in hist: # RF/LogReg\n",
        "                    val_auroc = np.array(hist['val_auroc'], dtype=float)\n",
        "                    train_auroc = np.array(hist['train_auroc'], dtype=float)\n",
        "                    sizes = np.array(hist['train_size'])\n",
        "                    best_idx = int(np.argmax(val_auroc))\n",
        "                    row = {\n",
        "                        'Strategy': strategy_name.capitalize(), 'Model': model_type, 'Subject_ID': subject_id,\n",
        "                        'Best_Train_Size': int(sizes[best_idx]),\n",
        "                        'Train_AUROC_Best': float(train_auroc[best_idx]), 'Val_AUROC_Best': float(val_auroc[best_idx]),\n",
        "                        'AUROC_Gap': float(train_auroc[best_idx] - val_auroc[best_idx])\n",
        "                    }\n",
        "                    trad_rows.append(row)\n",
        "\n",
        "    # Save Reports\n",
        "    if history_rows:\n",
        "        cnn_df = pd.DataFrame(history_rows)\n",
        "        # Consistent gap semantics: Use AUROC_Gap for overfitting check\n",
        "        cnn_df['Fit_Label'] = cnn_df.apply(lambda r: 'Likely overfitting' if r['AUROC_Gap'] > config.OVERFIT_GAP_THRESHOLD else ('Likely underfitting' if r['Val_AUROC_Best'] < config.UNDERFIT_AUROC_THRESHOLD else 'Reasonable fit'), axis=1)\n",
        "        cnn_df.to_csv(os.path.join(output_dir, 'cnn_learning_diagnostics.csv'), index=False)\n",
        "        print(\"\\nDeep Model Fit Summary:\")\n",
        "        print(cnn_df.groupby(['Strategy', 'Fit_Label'])['Subject_ID'].count())\n",
        "\n",
        "    if trad_rows:\n",
        "        trad_df = pd.DataFrame(trad_rows)\n",
        "        trad_df['Fit_Label'] = trad_df.apply(lambda r: 'Likely overfitting' if r['AUROC_Gap'] > config.OVERFIT_GAP_THRESHOLD else ('Likely underfitting' if r['Val_AUROC_Best'] < config.UNDERFIT_AUROC_THRESHOLD else 'Reasonable fit'), axis=1)\n",
        "        trad_df.to_csv(os.path.join(output_dir, 'traditional_learning_diagnostics.csv'), index=False)\n",
        "        print(\"\\nTraditional Model Fit Summary:\")\n",
        "        print(trad_df.groupby(['Strategy', 'Model', 'Fit_Label'])['Subject_ID'].count())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if len(infant_data) > 0:\n",
        "        start_time = time.time()\n",
        "        all_results = run_all_strategies()\n",
        "        print(f\"\\nCompleted in {(time.time() - start_time)/60:.1f} minutes.\")\n",
        "\n",
        "        if all_results:\n",
        "            # Save Aggregate CSV\n",
        "            df = pd.DataFrame(all_results)\n",
        "            results_path = os.path.join(OUTPUT_DIR, 'all_results.csv')\n",
        "            df.to_csv(results_path, index=False)\n",
        "\n",
        "            print(\"\\nSUMMARY STATS:\")\n",
        "            summary = df.groupby(['strategy', 'model'])['auroc'].agg(['mean', 'std', 'count'])\n",
        "            print(summary)\n",
        "            summary.to_csv(os.path.join(OUTPUT_DIR, 'summary_stats.csv'))\n",
        "\n",
        "            # Plot Feature Importance (RF Global)\n",
        "            print(\"\\nGenerating Global Feature Importance...\")\n",
        "            model = TraditionalML('Random Forest', config)\n",
        "            # Flatten all data for global importance\n",
        "            X_all = np.concatenate([d['X'] for d in infant_data.values()])\n",
        "            y_all = np.concatenate([d['y'] for d in infant_data.values()])\n",
        "\n",
        "            # Downsample for speed if dataset is huge\n",
        "            if len(y_all) > 20000:\n",
        "                idx = np.random.choice(len(y_all), 20000, replace=False)\n",
        "                X_all, y_all = X_all[idx], y_all[idx]\n",
        "\n",
        "            model.fit(X_all, y_all)\n",
        "\n",
        "            if hasattr(model.model, 'feature_importances_'):\n",
        "                imp = model.model.feature_importances_\n",
        "                names = model.feature_names # Use the property we defined\n",
        "\n",
        "                feat_df = pd.DataFrame({'Feature': names, 'Importance': imp}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                sns.barplot(x='Importance', y='Feature', data=feat_df.head(20))\n",
        "                plt.title(\"Top 20 Features (Global Random Forest)\")\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(OUTPUT_DIR, 'figures', 'feature_importance.png'), dpi=150)\n",
        "                plt.close() # Good practice to close figure\n",
        "                print(\"Feature importance saved.\")\n",
        "\n",
        "        # ================================================================\n",
        "        # DIAGNOSTICS & STATS (Moved inside check to prevent crashes)\n",
        "        # ================================================================\n",
        "\n",
        "        generate_diagnostics(OUTPUT_DIR)\n",
        "        plot_aggregate_learning_curves()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"STATISTICAL SIGNIFICANCE TESTING (PAIRED)\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        # Check if results exist before trying to load them\n",
        "        results_csv_path = os.path.join(OUTPUT_DIR, 'all_results.csv')\n",
        "\n",
        "        if os.path.exists(results_csv_path):\n",
        "            results_df = pd.read_csv(results_csv_path)\n",
        "\n",
        "            if 'subject_id' not in results_df.columns:\n",
        "                results_df['subject_id'] = results_df['test_infant'].fillna(results_df.get('infant', ''))\n",
        "\n",
        "            for model_name in config.MODELS:\n",
        "                print(f\"\\n{model_name}:\")\n",
        "                df_m = results_df[results_df['model'] == model_name]\n",
        "\n",
        "                try:\n",
        "                    pivot = df_m.pivot(index='subject_id', columns='strategy', values='auroc').dropna()\n",
        "\n",
        "                    if 'LOSO' in pivot.columns and 'Hybrid' in pivot.columns:\n",
        "                        stat, p = wilcoxon(pivot['LOSO'], pivot['Hybrid'])\n",
        "                        print(f\"  LOSO vs Hybrid (n={len(pivot)}): p={p:.4f} {'*' if p < 0.05 else ''}\")\n",
        "                        print(f\"    Mean Diff: {pivot['Hybrid'].mean() - pivot['LOSO'].mean():.4f}\")\n",
        "\n",
        "                    if 'LOSO' in pivot.columns and 'Temporal' in pivot.columns:\n",
        "                        stat, p = wilcoxon(pivot['LOSO'], pivot['Temporal'])\n",
        "                        print(f\"  LOSO vs Temporal (n={len(pivot)}): p={p:.4f} {'*' if p < 0.05 else ''}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  Could not run stats: {e}\")\n",
        "\n",
        "            plot_overfitting_analysis(results_df)\n",
        "\n",
        "        else:\n",
        "            print(\"No results file found (runs may have failed or been skipped).\")\n",
        "\n",
        "    print(\"Execution completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Useage Disclosure"
      ],
      "metadata": {
        "id": "cTaUi6JDBqxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### I used the following LLMs:\n",
        "\n",
        "* Opus 4.5\n",
        "* Sonnet 4.5\n",
        "* Gemini 2.5 & 3.0\n",
        "* ChatGPT 5.0 & 5.1\n",
        "* Google Colab AI code completion (Codey)\n",
        "\n",
        "#### For the following general tasks:\n",
        "* Brainstorming & planning\n",
        "* Autocomplete suggestions\n",
        "* Debugging/error explainations\n",
        "* Feedback & suggestions for improving code\n",
        "* Improveing readability (refactoring, commenting, etc.)\n",
        "* Optimizing runtime performance (e.g., vectorizing feature extraction)"
      ],
      "metadata": {
        "id": "TmUoyXEDBxOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specific LLM usages"
      ],
      "metadata": {
        "id": "S_McOCKRDTGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Readability:\n",
        "* Comments\n",
        "* Docstrings\n",
        "* Organizing\n",
        "* Refactoring\n",
        "* PEP 8 compliance\n",
        "* General tidying up & neatness\n",
        "* `print`s for logging/debugging\n",
        "* Making the outputs more readable (e.g., \"=\"*70)\n",
        "\n",
        "---\n",
        "\n",
        "#### Doublechecking for Potential Missed/Hidden Data Leakage Issues:\n",
        "* Asked all LLMs to check code for potential data leakage and suggest optimal ways of dealing with it (such as for the hybrid-splitting code in `run_all_strategies`).\n",
        "\n",
        "---\n",
        "\n",
        "#### Optimizing Runtime Speed/Performance:\n",
        "* Gemini 3 suggested & helped with vectorizing feature extraction & window generation (in `make_windows` & `_features`)\n",
        "* Automatic Mixed Precision (AMP) implementation\n",
        "\n",
        "---\n",
        "\n",
        "#### Preemptive/defensive coding & error handling:\n",
        "* Used LLMs to identify & improve parts of the code that might fail and could benefit from error handling safeguards (to avoid wasting time & GPU credits on long/overnight runs that end up crashing).\n",
        "\n",
        "---\n",
        "\n",
        "#### Google Drive integration:\n",
        "* At one point started getting some weird annoying \"mountpoint\" error in Collab. Used one of the LLMs (I think ChatGPT) to realize that it was probably due to some local ghost file (not sure why) and make the mounting code more robust.\n",
        "\n",
        "---\n",
        "\n",
        "#### Checkpoint logic:\n",
        "* LLMs helped with writing code to automatically save all potentially relevant training information to Google Drive, including:\n",
        "  * training history,\n",
        "  * `progresstracker` (w/ atomic file writes),\n",
        "  * automatic skip trainings that were already done.\n",
        "\n",
        "---\n",
        "\n",
        "#### Visualizations:\n",
        "* 4-panel diagnostic plots with automated overfitting detection: The code to place the \"DIAGNOSIS\" text box (ax4.text(...)) with manual coordinate transforms and bounding boxes (bbox=dict(boxstyle='round'...)).\n",
        "* Aggregate analysis with NaN-padding logic: The `plot_aggregate_learning_curves` function manually pads lists with np.nan to handle histories of different lengths (due to early stopping) before averaging them.\n",
        "* Functions like `plot_overfitting_analysis(results_df)` that use a particular column schema on `results_df` to make nicer figures.\n",
        "\n",
        "---\n",
        "\n",
        "#### Diagnosis Logic:\n",
        "* The `if/elif` block defining \"OVERFITTING\" vs \"UNDERFITTING\" based on thresholds is a literal translation of a requirement prompt.\n",
        "\n",
        "---\n",
        "\n",
        "#### TCN Suggestion:\n",
        "* LLMs suggested concatenating \"Global Average Pooling\" (GAP) and the \"Last Timestep\" to enable the model look at the whole history, while prioritizing the most recent second.\n",
        "\n",
        "---\n",
        "\n",
        "#### The `WeightedRandomSampler` Math:\n",
        "* Used LLMs to help with the `make_weighted_sampler_with_target` to get the exact sampling weights required to force a batch to have a specific ratio of positives, regardless of the dataset's actual imbalance.\n",
        "\n",
        "----\n",
        "\n",
        "#### Misc.:\n",
        "* Using a @dataclass for configuration"
      ],
      "metadata": {
        "id": "dp1t-mgVw8BM"
      }
    }
  ]
}